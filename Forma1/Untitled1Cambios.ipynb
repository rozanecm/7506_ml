{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "This notebooks uses the file generated by the notebook `process_dates_screen_storage.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import Area Under the Receiver Operating Characteristic Curve metric to evaluate results\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data...\n",
    "The files loaded are generated by the notebook `process_dates_screen_starge.ipynb`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/home/miki_mustard/Desktop/Facultad/Datos/TP2/train_df_processed_screenResol_storage_dates.csv')\n",
    "\n",
    "to_predict = pd.read_csv('/home/miki_mustard/Desktop/Facultad/Datos/TP2/to_predict_processed_screenResol_storage_dates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Note on preprocessing\n",
    "All preprocessing which can be done in just one way, i.e. it doesn't need hyper parameter adjustment, will be done outside pipelines and then stored to a new file, so there will be no need to execute the same code every time we open this notebook again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good pipeline resources: \n",
    "* http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html\n",
    "* https://www.kaggle.com/baghern/a-deep-dive-into-sklearn-pipelines\n",
    "* https://www.kaggle.com/metadist/work-like-a-pro-with-pipelines-and-feature-unions\n",
    "* https://www.kaggle.com/sermakarevich/sklearn-pipelines-tutorial\n",
    "* http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build some custom transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature pipeline creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.33\n",
    "# define a seed, so same experiments output same results every time and experiments between them become comparable\n",
    "seed = 12\n",
    "\n",
    "# realizo train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df.loc[:, train_df.columns != 'label'], \n",
    "                                                    train_df.label, \n",
    "                                                    test_size=test_size, \n",
    "                                                    random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hv = FeatureHasher(input_type='string')\n",
    "# hv.fit_transform(X_train.event.fillna(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['person', 'url', 'model', 'color', 'skus', 'search_term', 'city',\n",
       "       'region', 'country'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.select_dtypes('object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limited_categorical_transformer = Pipeline([\n",
    "#     (\"imputer\",SimpleImputer(strategy='most_frequent')),\n",
    "#     (\"one_hot\",OneHotEncoder(handle_unknown='ignore'))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# large_categorical_transformer = Pipeline([\n",
    "#     (\"imputer\",SimpleImputer(strategy='most_frequent')),\n",
    "#     (\"hashing_trci\",FeatureHasher(input_type='string'))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_idf = Pipeline([\n",
    "#     (\"imputer\",SimpleImputer(strategy='constant',fill_value=\"\")),\n",
    "#     (\"tf_idf\",TfidfVectorizer()),\n",
    "#     ('best', TruncatedSVD())\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ct = make_column_transformer(\n",
    "#     (\"large_cat\",large_categorical_transformer,[\"person\",\"skus\",\"city\",\"region\",\"country\"]),\n",
    "#     (TfidfVectorizer(),['model','color'])\n",
    "#     (\"tf_idf2\",tf_idf,'color'),\n",
    "#     (\"tf_idf_reduced\",TfidfVectorizer(),\"search_term\"),\n",
    "#     (\"ulr_tf\",TfidfVectorizer(),\"url\")\n",
    "\n",
    "#                        ,n_jobs=-1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.color.fillna(\"\", inplace=True)\n",
    "# X_train.model.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_tf = TfidfVectorizer()\n",
    "# my_tf.fit(X_train.color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_grid_search = random_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_processing = Pipeline([\n",
    "#     ('preproc', ct),\n",
    "    ('xg_reg', XGBRegressor(objective ='binary:logistic', learning_rate=0.1, booster='dart'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('xg_reg', XGBRegressor(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_processing.fit(X_train.select_dtypes(exclude='object'), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_reg = feature_processing.predict(X_test.select_dtypes(exclude='object'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = feature_processing.predict_proba(X_test.select_dtypes(exclude='object'))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes OK\n"
     ]
    }
   ],
   "source": [
    "# check shape of predictions\n",
    "if (preds_reg.shape == y_test.shape):\n",
    "    print('shapes OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8537931349192909"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prev: 0.8886417505271881\n",
    "#       0.7675200441464977\n",
    "#       0.8501359056263651\n",
    "#       0.9994019683472557    logistic_regression con preprocesamiento de browswer y os.\n",
    "#       0.8501359056263651    idem pero con xgb\n",
    "#       0.8503577934604342    xgb con:\n",
    "#                                     ct = ColumnTransformer([\n",
    "#                                         (\"lim_cat\",limited_categorical_transformer,[\"event\",\"condition\",\"staticpage\",\n",
    "#                                                                                     \"campaign_source\",\"search_engine\",\n",
    "#                                                                                     \"channel\",\"new_vs_returning\",\"device_type\",\n",
    "#                                                                                     \"operating_system_version\",\"browser_version\"]),\n",
    "#                                         (\"large_cat\",large_categorical_transformer,[\"person\",\"url\",\"skus\",\"city\",\"region\",\"country\"]),\n",
    "#                                         (\"tf_idf\",TfidfVectorizer(),\"model\"),\n",
    "#                                         (\"tf_idf2\",TfidfVectorizer(),\"color\"),\n",
    "#                                         (\"tf_idf_reduced\",TfidfVectorizer(),\"search_term\"),\n",
    "#                                         (\"passthrough\",'passthrough',[\"storage\",\"sku\",\"year\",\"month_sin\",\"month_cos\",\"day_sin\",\"day_cos\",\"weekday_sin\",\n",
    "#                                                                       \"weekday_cos\",\"hour_sin\",\"hour_cos\",\"screen_width\",\"screen_height\"])\n",
    "#                                     ],n_jobs=-1)\n",
    "roc_auc_score(y_test,preds_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_processing.named_steps['preproc'].named_transformers_['tf_idf'].idf_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_reg = feature_processing.predict(to_predict.select_dtypes(exclude='object'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds_posta = feature_processing.predict_proba(to_predict.select_dtypes(exclude='object'))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_posta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_publish = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_publish['person'] = to_predict.person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_publish['label'] = preds_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_publish.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_publish.groupby('person', as_index=False).mean().to_csv('prediccion_entrega6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
