{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import Area Under the Receiver Operating Characteristic Curve metric to evaluate results\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data...\n",
    "The files loaded are generated by the notebook `process_dates_screen_starge.ipynb`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    \"timestamp\":object,\n",
    "    \"event\":object,\n",
    "    \"person\":object,\n",
    "    \"url\":object,\n",
    "    \"sku\":float,\n",
    "    \"model\":object,\n",
    "    \"condition\":object,\n",
    "    \"storage\":float,\n",
    "    \"color\":object,\n",
    "    \"skus\":object,\n",
    "    \"search_term\":object,\n",
    "    \"staticpage\":object,\n",
    "    \"campaign_source\":object,\n",
    "    \"search_engine\":object,\n",
    "    \"channel\":object,\n",
    "    \"new_vs_returning\":object,\n",
    "    \"city\":object,\n",
    "    \"region\":object,\n",
    "    \"country\":object,\n",
    "    \"device_type\":object,\n",
    "    \"operating_system_version\":object,\n",
    "    \"browser_version\":object,\n",
    "    \"label\":int,\n",
    "    \"year\":int,\n",
    "    \"year_month_day\":object,\n",
    "    \"month_sin\":float,\n",
    "    \"month_cos\":float,\n",
    "    \"day_sin\":float,\n",
    "    \"day_cos\":float,\n",
    "    \"weekday_sin\":float,\n",
    "    \"weekday_cos\":float,\n",
    "    \"hour_sin\":float,\n",
    "    \"hour_cos\":float,\n",
    "    \"screen_width\":int,\n",
    "    \"screen_height\":int\n",
    "}\n",
    "train_df = pd.read_csv('data/train_df_processed_screenResol_storage_dates.csv', dtype=dtypes, parse_dates=['timestamp','year_month_day'])\n",
    "\n",
    "to_predict = pd.read_csv('data/to_predict_processed_screenResol_storage_dates.csv', dtype=dtypes, parse_dates=['timestamp','year_month_day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Note on preprocessing\n",
    "All preprocessing which can be done in just one way, i.e. it doesn't need hyper parameter adjustment, will be done outside pipelines and then stored to a new file, so there will be no need to execute the same code every time we open this notebook again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good pipeline resources: \n",
    "* http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html\n",
    "* https://www.kaggle.com/baghern/a-deep-dive-into-sklearn-pipelines\n",
    "* https://www.kaggle.com/metadist/work-like-a-pro-with-pipelines-and-feature-unions\n",
    "* https://www.kaggle.com/sermakarevich/sklearn-pipelines-tutorial\n",
    "* http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build some custom transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Selector to select the needed columns in the pipeline\n",
    "    \"\"\"\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.loc[:,self.cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class NaFiller(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Selector to select the needed columns in the pipeline\n",
    "    \"\"\"\n",
    "    def __init__(self, filler):\n",
    "        self.filler = filler\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.filler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature pipeline creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.33\n",
    "# define a seed, so same experiments output same results every time and experiments between them become comparable\n",
    "seed = 12\n",
    "\n",
    "# realizo train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df.loc[:, train_df.columns != 'label'], \n",
    "                                                    train_df.label, \n",
    "                                                    test_size=test_size, \n",
    "                                                    random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://www.kaggle.com/baghern/a-deep-dive-into-sklearn-pipelines:\n",
    "# To make a pipeline, just pass an array of tuples of the format (name, object). The first part is the name of the action, and the second is the actual object. \n",
    "\n",
    "screen_res_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['screen_width','screen_height']))\n",
    "])\n",
    "\n",
    "storage_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['storage']))\n",
    "])\n",
    "\n",
    "times_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['month_sin','month_cos','day_sin','day_cos','weekday_sin','weekday_cos','hour_sin','hour_cos']))\n",
    "])\n",
    "\n",
    "browser_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['browser_version'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('hasher', OneHotEncoder(handle_unknown='ignore')) \n",
    "])\n",
    "\n",
    "os_ver_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['operating_system_version'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('hasher', OneHotEncoder(handle_unknown='ignore')) \n",
    "])\n",
    "\n",
    "device_type_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['device_type'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore')) \n",
    "])\n",
    "\n",
    "country_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['country'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore')) \n",
    "])\n",
    "\n",
    "region_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['region'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "city_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['city'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "new_vs_returning_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['new_vs_returning'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "channel_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['channel'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "search_engine_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['search_engine'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "campaign_source_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['campaign_source'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "staticpage_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['staticpage'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "search_term_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['search_term'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "skus_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['skus'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "color_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['color'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "condition_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['condition'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "model_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['model'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "sku_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['sku'])),\n",
    "    ('na_filler', NaFiller(0)),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "url_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['url'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "person_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['person'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "event_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['event'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "feats = FeatureUnion([\n",
    "    ('time_related', times_pipe),\n",
    "    ('storage', storage_pipe),\n",
    "    ('screen', screen_res_pipe),\n",
    "    ('browser', browser_pipe),\n",
    "    ('os', os_ver_pipe),\n",
    "    ('device_type', device_type_pipe),\n",
    "    ('country', country_pipe),\n",
    "    ('region', region_pipe),\n",
    "    ('city', city_pipe),\n",
    "    ('new_vs_ret', new_vs_returning_pipe),\n",
    "    ('channel', channel_pipe),\n",
    "    ('search_eng', search_engine_pipe),\n",
    "    ('campaign', campaign_source_pipe),\n",
    "    ('staticpage', staticpage_pipe),\n",
    "    ('searchterm', search_term_pipe),\n",
    "    ('skus', skus_pipe),\n",
    "    ('color', color_pipe),\n",
    "    ('condition', condition_pipe),\n",
    "    ('model', model_pipe),\n",
    "    ('sku', sku_pipe),\n",
    "    ('url', url_pipe),\n",
    "    ('person', person_pipe),\n",
    "    ('event', event_pipe)\n",
    "])\n",
    "\n",
    "feature_processing = Pipeline([\n",
    "    ('feats', feats),\n",
    "    ('xg_reg', GradientBoostingClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('feats', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('time_related', Pipeline(memory=None,\n",
       "     steps=[('selector', ColumnSelector(cols=['month_sin', 'month_cos', 'day_sin', 'day_cos', 'weekday_sin', 'weekday_cos', 'hour_sin', 'hour_cos']))])), ('storage', Pipeline(memory=None, steps...    subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_processing.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = feature_processing.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes OK\n"
     ]
    }
   ],
   "source": [
    "# check shape of predictions\n",
    "if (preds.shape == y_test.shape):\n",
    "    print('shapes OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7675200441464977"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prev: 0.8886417505271881\n",
    "#       0.7675200441464977\n",
    "roc_auc_score(y_test,preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_posta = feature_processing.predict_proba(to_predict)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06769457, 0.06769457, 0.06769457, ..., 0.06769457, 0.06769457,\n",
       "       0.06769457])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_posta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_publish = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_publish['person'] = to_predict.person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_publish['label'] = preds_posta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_publish.groupby('person', as_index=False).mean().to_csv('predictions/with_numeric_xgb3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
