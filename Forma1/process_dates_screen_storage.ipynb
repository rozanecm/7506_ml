{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df = pd.read_csv('data/events_up_to_01062018.csv', low_memory=False)\n",
    "labels_df = pd.read_csv('data/labels_training_set.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# armo df con registros completos clasificados\n",
    "train_df = events_df.merge(labels_df, on='person', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# armo df con registros a predecir unicamente\n",
    "to_predict = events_df[~events_df['person'].isin(labels_df.person)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some date processing\n",
    "def date_proc(df):\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['year'] = df['timestamp'].dt.year\n",
    "    df['month'] = df['timestamp'].dt.month\n",
    "    df['day'] = df['timestamp'].dt.day\n",
    "    df['weekday'] = df['timestamp'].dt.day_name()\n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "    df['year_month_day'] = df['timestamp'].map(lambda x: str(x.year)+\"/\"+str(x.month)+\"/\"+str(x.day))\n",
    "    df['year_month_day'] = pd.to_datetime(df['year_month_day'])\n",
    "    \n",
    "date_proc(train_df)\n",
    "date_proc(to_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero hacemos un label encoding con el weekday, luego aplicamos una transfrmacion que contemple la naturaleza ciclica de la semana. Esto ultimo lo aplicaremos tambien al resto de los features ciclicos (como se explica, por ejemplo, aca: https://ianlondon.github.io/blog/encoding-cyclical-features-24hour-time/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_le = preprocessing.LabelEncoder()\n",
    "weekday_le.fit(train_df.weekday)\n",
    "\n",
    "train_df.weekday = weekday_le.transform(train_df.weekday)\n",
    "to_predict.weekday = weekday_le.transform(to_predict.weekday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_to_cyclic(df):\n",
    "    df['month_sin'] = df['month'].apply(lambda x: np.sin(2*np.pi*x/12))\n",
    "    df['month_cos'] = df['month'].apply(lambda x: np.cos(2*np.pi*x/12))\n",
    "    df.drop('month', axis=1, inplace=True)\n",
    "    \n",
    "def day_to_cyclic(df):\n",
    "    df['day_sin'] = df['day'].apply(lambda x: np.sin(2*np.pi*x/31))\n",
    "    df['day_cos'] = df['day'].apply(lambda x: np.cos(2*np.pi*x/31))\n",
    "    df.drop('day', axis=1, inplace=True)\n",
    "\n",
    "def weekday_to_cyclic(df):\n",
    "    df['weekday_sin'] = df['weekday'].apply(lambda x: np.sin(2*np.pi*x/7))\n",
    "    df['weekday_cos'] = df['weekday'].apply(lambda x: np.cos(2*np.pi*x/7))\n",
    "    df.drop('weekday', axis=1, inplace=True)\n",
    "\n",
    "def hour_to_cyclic(df):\n",
    "    df['hour_sin'] = df['hour'].apply(lambda x: np.sin(2*np.pi*x/24))\n",
    "    df['hour_cos'] = df['hour'].apply(lambda x: np.cos(2*np.pi*x/24))\n",
    "    df.drop('hour', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell to compare results before & after processing\n",
    "# train_df[['year','month','day','weekday','hour']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_to_cyclic(train_df)\n",
    "day_to_cyclic(train_df)\n",
    "weekday_to_cyclic(train_df)\n",
    "hour_to_cyclic(train_df)\n",
    "\n",
    "month_to_cyclic(to_predict)\n",
    "day_to_cyclic(to_predict)\n",
    "weekday_to_cyclic(to_predict)\n",
    "hour_to_cyclic(to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df[['month_sin','month_cos','day_sin','day_cos','weekday_sin','weekday_cos','hour_sin','hour_cos']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.drop('year_month_day', axis=1, inplace=True)\n",
    "# to_predict.drop('year_month_day', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## screen_resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_screen_width(x):\n",
    "    if x != \"\":\n",
    "        return int(x.split(\"x\")[0])\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def get_screen_height(x):\n",
    "    if x != \"\":\n",
    "        return int(x.split(\"x\")[1])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def process_screen_res(df):\n",
    "    df['screen_resolution'].fillna(\"\", inplace=True)\n",
    "    df['screen_width'] = df['screen_resolution'].apply(lambda x: get_screen_width(x))\n",
    "    df['screen_height'] = df['screen_resolution'].apply(lambda x: get_screen_height(x))\n",
    "    df.drop('screen_resolution', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_screen_res(train_df)\n",
    "process_screen_res(to_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_storage_string(x):\n",
    "    if pd.isna(x):\n",
    "        return 0\n",
    "    s = x.split(\"GB\")\n",
    "    if len(s) == 2:\n",
    "        # case data in GB\n",
    "        return int(s[0])\n",
    "    else:\n",
    "        # case data in MB\n",
    "        return int(x.split(\"MB\")[0])/1024\n",
    "\n",
    "def storage_process(df):\n",
    "    df.storage = df.storage.apply(lambda x: process_storage_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_process(train_df)\n",
    "storage_process(to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('data/train_df_processed_screenResol_storage_dates.csv', index=False)\n",
    "to_predict.to_csv('data/to_predict_processed_screenResol_storage_dates.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
