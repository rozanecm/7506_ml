{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "This notebooks uses the file generated by the notebook `process_dates_screen_storage.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import Area Under the Receiver Operating Characteristic Curve metric to evaluate results\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data...\n",
    "The files loaded are generated by the notebook `process_dates_screen_starge.ipynb`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    \"timestamp\":object,\n",
    "    \"event\":object,\n",
    "    \"person\":object,\n",
    "    \"url\":object,\n",
    "    \"sku\":float,\n",
    "    \"model\":object,\n",
    "    \"condition\":object,\n",
    "    \"storage\":float,\n",
    "    \"color\":object,\n",
    "    \"skus\":object,\n",
    "    \"search_term\":object,\n",
    "    \"staticpage\":object,\n",
    "    \"campaign_source\":object,\n",
    "    \"search_engine\":object,\n",
    "    \"channel\":object,\n",
    "    \"new_vs_returning\":object,\n",
    "    \"city\":object,\n",
    "    \"region\":object,\n",
    "    \"country\":object,\n",
    "    \"device_type\":object,\n",
    "    \"operating_system_version\":object,\n",
    "    \"browser_version\":object,\n",
    "    \"label\":int,\n",
    "    \"year\":int,\n",
    "    \"year_month_day\":object,\n",
    "    \"month_sin\":float,\n",
    "    \"month_cos\":float,\n",
    "    \"day_sin\":float,\n",
    "    \"day_cos\":float,\n",
    "    \"weekday_sin\":float,\n",
    "    \"weekday_cos\":float,\n",
    "    \"hour_sin\":float,\n",
    "    \"hour_cos\":float,\n",
    "    \"screen_width\":int,\n",
    "    \"screen_height\":int\n",
    "}\n",
    "train_df = pd.read_csv('data/train_df_processed_screenResol_storage_dates.csv', dtype=dtypes, parse_dates=['timestamp','year_month_day'])\n",
    "\n",
    "to_predict = pd.read_csv('data/to_predict_processed_screenResol_storage_dates.csv', dtype=dtypes, parse_dates=['timestamp','year_month_day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Note on preprocessing\n",
    "All preprocessing which can be done in just one way, i.e. it doesn't need hyper parameter adjustment, will be done outside pipelines and then stored to a new file, so there will be no need to execute the same code every time we open this notebook again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good pipeline resources: \n",
    "* http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html\n",
    "* https://www.kaggle.com/baghern/a-deep-dive-into-sklearn-pipelines\n",
    "* https://www.kaggle.com/metadist/work-like-a-pro-with-pipelines-and-feature-unions\n",
    "* https://www.kaggle.com/sermakarevich/sklearn-pipelines-tutorial\n",
    "* http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build some custom transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Selector to select the needed columns in the pipeline\n",
    "    \"\"\"\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.loc[:,self.cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class NaFiller(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Selector to select the needed columns in the pipeline\n",
    "    \"\"\"\n",
    "    def __init__(self, filler):\n",
    "        self.filler = filler\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.filler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature pipeline creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.33\n",
    "# define a seed, so same experiments output same results every time and experiments between them become comparable\n",
    "seed = 12\n",
    "\n",
    "# realizo train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df.loc[:, train_df.columns != 'label'], \n",
    "                                                    train_df.label, \n",
    "                                                    test_size=test_size, \n",
    "                                                    random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785163, 34)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785163, 34)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hv = HashingVectorizer(decode_error='ignore')\n",
    "# hv.fit_transform(X_train.browser_version.fillna(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://www.kaggle.com/baghern/a-deep-dive-into-sklearn-pipelines:\n",
    "# To make a pipeline, just pass an array of tuples of the format (name, object). The first part is the name of the action, and the second is the actual object. \n",
    "\n",
    "screen_res_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['screen_width','screen_height']))\n",
    "])\n",
    "\n",
    "storage_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['storage']))\n",
    "])\n",
    "\n",
    "times_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['month_sin','month_cos','day_sin','day_cos','weekday_sin','weekday_cos','hour_sin','hour_cos']))\n",
    "])\n",
    "\n",
    "browser_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['browser_version'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "os_ver_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['operating_system_version'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "device_type_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['device_type'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "country_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['country'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore')) \n",
    "])\n",
    "\n",
    "region_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['region'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "city_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['city'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "new_vs_returning_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['new_vs_returning'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "channel_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['channel'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "search_engine_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['search_engine'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "campaign_source_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['campaign_source'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "staticpage_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['staticpage'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "search_term_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['search_term'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('tf_idf', TfidfVectorizer())\n",
    "])\n",
    "\n",
    "skus_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['skus'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "color_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['color'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "condition_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['condition'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "model_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['model'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "sku_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['sku'])),\n",
    "    ('na_filler', NaFiller(0)),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "url_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['url'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "person_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['person'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "event_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(['event'])),\n",
    "    ('na_filler', NaFiller(\"\")),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "feats = FeatureUnion([\n",
    "    ('time_related', times_pipe),\n",
    "    ('storage', storage_pipe),\n",
    "    ('screen', screen_res_pipe),\n",
    "    ('browser', browser_pipe),\n",
    "    ('os', os_ver_pipe),\n",
    "    ('device_type', device_type_pipe),\n",
    "    ('country', country_pipe),\n",
    "    ('region', region_pipe),\n",
    "    ('city', city_pipe),\n",
    "    ('new_vs_ret', new_vs_returning_pipe),\n",
    "    ('channel', channel_pipe),\n",
    "    ('search_eng', search_engine_pipe),\n",
    "    ('campaign', campaign_source_pipe),\n",
    "    ('staticpage', staticpage_pipe),\n",
    "    ('searchterm', search_term_pipe),\n",
    "    ('skus', skus_pipe),\n",
    "    ('color', color_pipe),\n",
    "    ('condition', condition_pipe),\n",
    "    ('model', model_pipe),\n",
    "    ('sku', sku_pipe),\n",
    "    ('url', url_pipe),\n",
    "    ('person', person_pipe),\n",
    "    ('event', event_pipe)\n",
    "])\n",
    "\n",
    "feature_processing = Pipeline([\n",
    "    ('feats', feats),\n",
    "    ('xg_reg', XGBClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "blocks[0,:] has incompatible row dimensions. Got blocks[0,14].shape[0] == 1, expected 785163.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-610a7551c285>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeature_processing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Univerza/UBA/7506 Organizacion de Datos/2018/ml_tp/venv/lib/python3.5/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Univerza/UBA/7506 Organizacion de Datos/2018/ml_tp/venv/lib/python3.5/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    228\u001b[0m                 Xt, fitted_transformer = fit_transform_one_cached(\n\u001b[1;32m    229\u001b[0m                     \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                     **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    231\u001b[0m                 \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Univerza/UBA/7506 Organizacion de Datos/2018/ml_tp/venv/lib/python3.5/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Univerza/UBA/7506 Organizacion de Datos/2018/ml_tp/venv/lib/python3.5/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Univerza/UBA/7506 Organizacion de Datos/2018/ml_tp/venv/lib/python3.5/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_transformer_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mXs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             \u001b[0mXs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0mXs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Univerza/UBA/7506 Organizacion de Datos/2018/ml_tp/venv/lib/python3.5/site-packages/scipy/sparse/construct.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(blocks, format, dtype)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \"\"\"\n\u001b[0;32m--> 464\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Univerza/UBA/7506 Organizacion de Datos/2018/ml_tp/venv/lib/python3.5/site-packages/scipy/sparse/construct.py\u001b[0m in \u001b[0;36mbmat\u001b[0;34m(blocks, format, dtype)\u001b[0m\n\u001b[1;32m    583\u001b[0m                                                     \u001b[0mexp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbrow_lengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m                                                     got=A.shape[0]))\n\u001b[0;32m--> 585\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbcol_lengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: blocks[0,:] has incompatible row dimensions. Got blocks[0,14].shape[0] == 1, expected 785163."
     ]
    }
   ],
   "source": [
    "feature_processing.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = feature_processing.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes OK\n"
     ]
    }
   ],
   "source": [
    "# check shape of predictions\n",
    "if (preds.shape == y_test.shape):\n",
    "    print('shapes OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8501359056263651"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prev: 0.8886417505271881\n",
    "#       0.7675200441464977\n",
    "#       0.8501359056263651\n",
    "#       0.9994019683472557    logistic_regression con preprocesamiento de browswer y os.\n",
    "roc_auc_score(y_test,preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_posta = feature_processing.predict_proba(to_predict)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06565948, 0.06565948, 0.06565948, ..., 0.07162312, 0.07162312,\n",
       "       0.07162312], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_posta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_publish = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_publish['person'] = to_predict.person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_publish['label'] = preds_posta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_publish.groupby('person', as_index=False).mean().to_csv('predictions/29.nov@15.53.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
